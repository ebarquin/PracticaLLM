# Fine-Tuning Falcon-RW-1B con LoRA para Recomendaci√≥n de Tarifas El√©ctricas

Este proyecto tiene como objetivo el fine-tuning de un modelo de lenguaje para adaptarlo a una tarea espec√≠fica: **recomendar la tarifa el√©ctrica m√°s adecuada en funci√≥n de una descripci√≥n de los h√°bitos de consumo del usuario**.

Se parte del modelo [Falcon-RW-1B](https://huggingface.co/tiiuae/falcon-rw-1b), el cual ha sido afinado con datos sint√©ticos para que, dado un prompt como:

> ‚ÄúTengo consumo alto por la noche, ¬øqu√© tarifa recomiendas?‚Äù

El modelo sea capaz de responder con:

> ‚ÄúLa tarifa nocturna es la m√°s adecuada para ti, ya que aprovecha precios reducidos en horario nocturno.‚Äù

## üìÇ Contenido del repositorio

- `PracticaLLM.ipynb`: Notebook con todo el proceso de entrenamiento, validaci√≥n y subida del modelo a Hugging Face.
- `tarifas_finetune_clean.jsonl`: Dataset sint√©tico utilizado para el fine-tuning.
- `tarifas_reales.csv`: CSV con tarifas reales usado como referencia para generar los datos de entrenamiento.
- `modelo-finetuneado/`: Carpeta generada por Hugging Face Transformers con los pesos LoRA entrenados.

## üß† Modelo base

- **Nombre**: `tiiuae/falcon-rw-1b`
- **Par√°metros**: 1.3B
- **Tipo**: Causal Language Model (CLM)
- **Token especial de padding**: igual al token de fin de secuencia (`eos_token`)

## ‚öôÔ∏è T√©cnica de fine-tuning

Se ha utilizado **LoRA (Low-Rank Adaptation)**, una t√©cnica de entrenamiento eficiente para adaptar modelos grandes sin modificar directamente sus pesos base. Configuraci√≥n utilizada:

- `r=8`
- `alpha=32`
- `target_modules=["query_key_value"]`
- `dropout=0.05`

## üß™ Validaci√≥n

El modelo fue entrenado con un conjunto sint√©tico de 100 ejemplos, y posteriormente validado con una fracci√≥n separada del dataset. Los resultados mostraron una mejora constante y reducci√≥n del error:

| Epoch | Training Loss | Validation Loss |
|-------|----------------|------------------|
| 1     | 0.1934         | 0.1721           |
| 2     | 0.0233         | 0.0217           |
| 3     | 0.0142         | 0.0127           |
| 4     | 0.0126         | 0.0126           |

‚ö†Ô∏è **Nota**: Los resultados son prometedores, pero deben tomarse con cautela. El dataset es muy homog√©neo, lo que facilita que el modelo aprenda r√°pidamente. En un entorno real, se requerir√≠a un dataset m√°s diverso y representativo de casos reales.

## üìä Dataset

- `tarifas_finetune_clean.jsonl`: contiene 500 ejemplos sint√©ticos del formato:
  ```json
  {
    "prompt": "Tengo consumo alto por la noche, ¬øqu√© tarifa recomiendas?",
    "completion": "La tarifa nocturna es la m√°s adecuada para ti, ya que aprovecha precios reducidos en horario nocturno."
  }
  ```

- `tarifas_reales.csv`: contiene las tarifas el√©ctricas reales que sirvieron como inspiraci√≥n para generar el dataset.

üîß **Pendiente**: El objetivo inicial era construir el dataset a partir de scraping de p√°ginas web de comercializadoras el√©ctricas (como Iberdrola, Repsol o TotalEnergies). Por falta de tiempo, se opt√≥ por crear datos sint√©ticos como sustituto. Esta funcionalidad queda pendiente para una futura versi√≥n del proyecto.

## üîê Requisitos de autenticaci√≥n

Este proyecto requiere dos claves de acceso:

- **Token de Hugging Face**: para descargar el modelo base `falcon-rw-1b`. Debe tener permisos para acceder a modelos protegidos. Puedes obtenerlo en [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens).
- **Token de OpenAI**: si planeas integrar este modelo o hacer comparativas con modelos OpenAI (opcional pero √∫til en evaluaciones). Puede obtenerse desde [platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys).

## üöÄ Pr√≥ximos pasos

- Ampliar el dataset sint√©tico para mayor robustez.
- Desarrollar el sistema de scraping para obtener informaci√≥n actualizada directamente desde webs oficiales.
- Evaluar m√©tricas espec√≠ficas de generaci√≥n (e.g., Rouge, BLEU).
- Probar modelos m√°s eficientes como `mistralai/Mistral-7B-Instruct` o `microsoft/phi-2`.
- Implementar una API o frontend para recomendaciones en tiempo real.