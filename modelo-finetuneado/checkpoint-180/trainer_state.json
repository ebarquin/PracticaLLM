{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 180,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 26.868410110473633,
      "learning_rate": 4.8611111111111115e-05,
      "loss": 5.4912,
      "step": 5
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 36.259334564208984,
      "learning_rate": 4.722222222222222e-05,
      "loss": 3.0894,
      "step": 10
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 5.028439521789551,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 0.8974,
      "step": 15
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 4.272880554199219,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.4004,
      "step": 20
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 1.114304780960083,
      "learning_rate": 4.305555555555556e-05,
      "loss": 0.3581,
      "step": 25
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.5514165759086609,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.3028,
      "step": 30
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 0.6677245497703552,
      "learning_rate": 4.027777777777778e-05,
      "loss": 0.2623,
      "step": 35
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.531627893447876,
      "learning_rate": 3.888888888888889e-05,
      "loss": 0.2212,
      "step": 40
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.49089139699935913,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.1934,
      "step": 45
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.17206427454948425,
      "eval_runtime": 6.0264,
      "eval_samples_per_second": 1.659,
      "eval_steps_per_second": 0.332,
      "step": 45
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.5150730609893799,
      "learning_rate": 3.611111111111111e-05,
      "loss": 0.1619,
      "step": 50
    },
    {
      "epoch": 1.2222222222222223,
      "grad_norm": 0.5946528911590576,
      "learning_rate": 3.472222222222222e-05,
      "loss": 0.1235,
      "step": 55
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.6091213226318359,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0915,
      "step": 60
    },
    {
      "epoch": 1.4444444444444444,
      "grad_norm": 0.45484891533851624,
      "learning_rate": 3.194444444444444e-05,
      "loss": 0.0723,
      "step": 65
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 0.44561293721199036,
      "learning_rate": 3.055555555555556e-05,
      "loss": 0.0523,
      "step": 70
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.4671652913093567,
      "learning_rate": 2.916666666666667e-05,
      "loss": 0.0387,
      "step": 75
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 0.45686841011047363,
      "learning_rate": 2.777777777777778e-05,
      "loss": 0.0288,
      "step": 80
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 0.6803333163261414,
      "learning_rate": 2.6388888888888892e-05,
      "loss": 0.025,
      "step": 85
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.40347960591316223,
      "learning_rate": 2.5e-05,
      "loss": 0.0233,
      "step": 90
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.02167159877717495,
      "eval_runtime": 3.625,
      "eval_samples_per_second": 2.759,
      "eval_steps_per_second": 0.552,
      "step": 90
    },
    {
      "epoch": 2.111111111111111,
      "grad_norm": 0.37106233835220337,
      "learning_rate": 2.361111111111111e-05,
      "loss": 0.0186,
      "step": 95
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.49783894419670105,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.0178,
      "step": 100
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 0.3669010102748871,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 0.0168,
      "step": 105
    },
    {
      "epoch": 2.4444444444444446,
      "grad_norm": 0.4318346381187439,
      "learning_rate": 1.9444444444444445e-05,
      "loss": 0.0142,
      "step": 110
    },
    {
      "epoch": 2.5555555555555554,
      "grad_norm": 0.32095664739608765,
      "learning_rate": 1.8055555555555555e-05,
      "loss": 0.0156,
      "step": 115
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.42207732796669006,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0148,
      "step": 120
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.32302358746528625,
      "learning_rate": 1.527777777777778e-05,
      "loss": 0.013,
      "step": 125
    },
    {
      "epoch": 2.888888888888889,
      "grad_norm": 0.47710829973220825,
      "learning_rate": 1.388888888888889e-05,
      "loss": 0.0138,
      "step": 130
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.44076451659202576,
      "learning_rate": 1.25e-05,
      "loss": 0.0142,
      "step": 135
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.012700758874416351,
      "eval_runtime": 3.5794,
      "eval_samples_per_second": 2.794,
      "eval_steps_per_second": 0.559,
      "step": 135
    },
    {
      "epoch": 3.111111111111111,
      "grad_norm": 0.5625176429748535,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 0.013,
      "step": 140
    },
    {
      "epoch": 3.2222222222222223,
      "grad_norm": 0.465328186750412,
      "learning_rate": 9.722222222222223e-06,
      "loss": 0.0125,
      "step": 145
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.3656776249408722,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.0121,
      "step": 150
    },
    {
      "epoch": 3.4444444444444446,
      "grad_norm": 0.363898366689682,
      "learning_rate": 6.944444444444445e-06,
      "loss": 0.0123,
      "step": 155
    },
    {
      "epoch": 3.5555555555555554,
      "grad_norm": 0.34254878759384155,
      "learning_rate": 5.555555555555556e-06,
      "loss": 0.0119,
      "step": 160
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 0.318742573261261,
      "learning_rate": 4.166666666666667e-06,
      "loss": 0.0112,
      "step": 165
    },
    {
      "epoch": 3.7777777777777777,
      "grad_norm": 0.5165229439735413,
      "learning_rate": 2.777777777777778e-06,
      "loss": 0.0124,
      "step": 170
    },
    {
      "epoch": 3.888888888888889,
      "grad_norm": 0.3841979503631592,
      "learning_rate": 1.388888888888889e-06,
      "loss": 0.0122,
      "step": 175
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.633240818977356,
      "learning_rate": 0.0,
      "loss": 0.0126,
      "step": 180
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.012583640404045582,
      "eval_runtime": 3.8461,
      "eval_samples_per_second": 2.6,
      "eval_steps_per_second": 0.52,
      "step": 180
    }
  ],
  "logging_steps": 5,
  "max_steps": 180,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1338357275688960.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
